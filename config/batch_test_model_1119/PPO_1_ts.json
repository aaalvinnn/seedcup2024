{
    "config_name": "PPO-1-ts",
    "algorithm": "PPO",
    "actor_lr": 2e-5,
    "critic_lr": 5e-5,
    "num_episodes": 3000,
    "state_dim": 12,
    "actor_hidden_dim": 64,
    "critic_hidden_dim": 64,
    "action_dim": 6,
    "num_actor_hidden_layers": 4,
    "num_critic_hidden_layers": 4,
    "gamma": 0.98,
    "lmbda": 0.95,
    "residual_strength": 0,
    "epochs": 15,
    "eps": 0.2,
    "n_state_steps": 3
}
